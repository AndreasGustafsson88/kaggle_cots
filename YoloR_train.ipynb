{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22627a3a",
   "metadata": {
    "papermill": {
     "duration": 0.037022,
     "end_time": "2022-01-06T15:52:35.738785",
     "exception": false,
     "start_time": "2022-01-06T15:52:35.701763",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### YoloR\n",
    "\n",
    "* Prepare COTS dataset for YoloR training\n",
    "* Install YoloR (YoloR, MISH CUDA, pytorch_wavelets)\n",
    "* Download Pre-Trained Weights for YoloR HUB\n",
    "* Prepare configuration files (YoloR hyperparameters and dataset)\n",
    "* Weights and Biases configuration for training logging\n",
    "* YoloR training\n",
    "* Run YoloR inference on test images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6fe044",
   "metadata": {
    "papermill": {
     "duration": 0.034258,
     "end_time": "2022-01-06T15:52:35.876747",
     "exception": false,
     "start_time": "2022-01-06T15:52:35.842489",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4fdce34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-06T15:52:35.961092Z",
     "iopub.status.busy": "2022-01-06T15:52:35.959876Z",
     "iopub.status.idle": "2022-01-06T15:52:35.985419Z",
     "shell.execute_reply": "2022-01-06T15:52:35.984752Z",
     "shell.execute_reply.started": "2022-01-06T13:46:00.033362Z"
    },
    "papermill": {
     "duration": 0.074953,
     "end_time": "2022-01-06T15:52:35.985583",
     "exception": false,
     "start_time": "2022-01-06T15:52:35.910630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.core.magic import register_line_cell_magic\n",
    "from shutil import copyfile\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd93ba3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-06T15:52:36.061611Z",
     "iopub.status.busy": "2022-01-06T15:52:36.060546Z",
     "iopub.status.idle": "2022-01-06T15:52:36.063168Z",
     "shell.execute_reply": "2022-01-06T15:52:36.063619Z",
     "shell.execute_reply.started": "2022-01-06T13:46:00.080821Z"
    },
    "papermill": {
     "duration": 0.042159,
     "end_time": "2022-01-06T15:52:36.063771",
     "exception": false,
     "start_time": "2022-01-06T15:52:36.021612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "HOME_DIR = '/kaggle/working'\n",
    "COTS_DATASET_PATH = '/kaggle/input/tensorflow-great-barrier-reef/train_images'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee5d2d7",
   "metadata": {
    "papermill": {
     "duration": 0.034902,
     "end_time": "2022-01-06T15:52:36.133690",
     "exception": false,
     "start_time": "2022-01-06T15:52:36.098788",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "545e2c34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-06T15:52:36.209177Z",
     "iopub.status.busy": "2022-01-06T15:52:36.208496Z",
     "iopub.status.idle": "2022-01-06T15:52:36.333638Z",
     "shell.execute_reply": "2022-01-06T15:52:36.334238Z",
     "shell.execute_reply.started": "2022-01-06T13:46:00.086719Z"
    },
    "papermill": {
     "duration": 0.165222,
     "end_time": "2022-01-06T15:52:36.334426",
     "exception": false,
     "start_time": "2022-01-06T15:52:36.169204",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>video_frame</th>\n",
       "      <th>sequence_frame</th>\n",
       "      <th>image_id</th>\n",
       "      <th>annotations</th>\n",
       "      <th>n_annotations</th>\n",
       "      <th>has_annotations</th>\n",
       "      <th>image_path</th>\n",
       "      <th>subsequence_id</th>\n",
       "      <th>is_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>40258</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0-0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>../input/tensorflow-great-barrier-reef/train_i...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>40258</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>../input/tensorflow-great-barrier-reef/train_i...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>40258</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0-2</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>../input/tensorflow-great-barrier-reef/train_i...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   video_id  sequence  video_frame  sequence_frame image_id annotations  \\\n",
       "0         0     40258            0               0      0-0          []   \n",
       "1         0     40258            1               1      0-1          []   \n",
       "2         0     40258            2               2      0-2          []   \n",
       "\n",
       "   n_annotations  has_annotations  \\\n",
       "0              0            False   \n",
       "1              0            False   \n",
       "2              0            False   \n",
       "\n",
       "                                          image_path  subsequence_id  is_train  \n",
       "0  ../input/tensorflow-great-barrier-reef/train_i...               1      True  \n",
       "1  ../input/tensorflow-great-barrier-reef/train_i...               1      True  \n",
       "2  ../input/tensorflow-great-barrier-reef/train_i...               1      True  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../input/reef-cv-strategy-subsequences-dataframes/train-validation-split/train-0.1.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "526528e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-06T15:52:36.415864Z",
     "iopub.status.busy": "2022-01-06T15:52:36.414681Z",
     "iopub.status.idle": "2022-01-06T15:52:37.571422Z",
     "shell.execute_reply": "2022-01-06T15:52:37.570799Z",
     "shell.execute_reply.started": "2022-01-06T13:46:00.215179Z"
    },
    "papermill": {
     "duration": 1.201128,
     "end_time": "2022-01-06T15:52:37.571562",
     "exception": false,
     "start_time": "2022-01-06T15:52:36.370434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New path and annotations preprocessing completed\n"
     ]
    }
   ],
   "source": [
    "def add_path(row):\n",
    "    return f\"{COTS_DATASET_PATH}/video_{row.video_id}/{row.video_frame}.jpg\"\n",
    "\n",
    "def num_boxes(annotations):\n",
    "    annotations = ast.literal_eval(annotations)\n",
    "    return len(annotations)\n",
    "\n",
    "df['path'] = df.apply(lambda row: add_path(row), axis=1)\n",
    "df['num_bbox'] = df['annotations'].apply(lambda x: num_boxes(x))\n",
    "print(\"New path and annotations preprocessing completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b47ba026",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-06T15:52:37.652241Z",
     "iopub.status.busy": "2022-01-06T15:52:37.650871Z",
     "iopub.status.idle": "2022-01-06T15:52:37.661535Z",
     "shell.execute_reply": "2022-01-06T15:52:37.662076Z",
     "shell.execute_reply.started": "2022-01-06T13:46:01.205766Z"
    },
    "papermill": {
     "duration": 0.053601,
     "end_time": "2022-01-06T15:52:37.662251",
     "exception": false,
     "start_time": "2022-01-06T15:52:37.608650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset images with annotations: 4919\n"
     ]
    }
   ],
   "source": [
    "df = df[df.num_bbox > 0]\n",
    "\n",
    "print(f'Dataset images with annotations: {len(df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ff5cb24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-06T15:52:37.747854Z",
     "iopub.status.busy": "2022-01-06T15:52:37.741773Z",
     "iopub.status.idle": "2022-01-06T15:52:37.905552Z",
     "shell.execute_reply": "2022-01-06T15:52:37.906438Z",
     "shell.execute_reply.started": "2022-01-06T13:46:01.220719Z"
    },
    "papermill": {
     "duration": 0.207873,
     "end_time": "2022-01-06T15:52:37.906645",
     "exception": false,
     "start_time": "2022-01-06T15:52:37.698772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New image path for train/valid created\n"
     ]
    }
   ],
   "source": [
    "def add_new_path(row):\n",
    "    if row.is_train:\n",
    "        return f\"{HOME_DIR}/yolor_dataset/images/train/{row.image_id}.jpg\"\n",
    "    else: \n",
    "        return f\"{HOME_DIR}/yolor_dataset/images/valid/{row.image_id}.jpg\"\n",
    "    \n",
    "\n",
    "df['new_path'] = df.apply(lambda row: add_new_path(row), axis=1)\n",
    "print(\"New image path for train/valid created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b69ea886",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-06T15:52:37.997874Z",
     "iopub.status.busy": "2022-01-06T15:52:37.996891Z",
     "iopub.status.idle": "2022-01-06T15:52:38.000885Z",
     "shell.execute_reply": "2022-01-06T15:52:38.001617Z",
     "shell.execute_reply.started": "2022-01-06T13:46:01.349496Z"
    },
    "papermill": {
     "duration": 0.05854,
     "end_time": "2022-01-06T15:52:38.001829",
     "exception": false,
     "start_time": "2022-01-06T15:52:37.943289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>video_frame</th>\n",
       "      <th>sequence_frame</th>\n",
       "      <th>image_id</th>\n",
       "      <th>annotations</th>\n",
       "      <th>n_annotations</th>\n",
       "      <th>has_annotations</th>\n",
       "      <th>image_path</th>\n",
       "      <th>subsequence_id</th>\n",
       "      <th>is_train</th>\n",
       "      <th>path</th>\n",
       "      <th>num_bbox</th>\n",
       "      <th>new_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>40258</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0-16</td>\n",
       "      <td>[{'x': 559, 'y': 213, 'width': 50, 'height': 32}]</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>../input/tensorflow-great-barrier-reef/train_i...</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>/kaggle/input/tensorflow-great-barrier-reef/tr...</td>\n",
       "      <td>1</td>\n",
       "      <td>/kaggle/working/yolor_dataset/images/train/0-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>40258</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0-17</td>\n",
       "      <td>[{'x': 558, 'y': 213, 'width': 50, 'height': 32}]</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>../input/tensorflow-great-barrier-reef/train_i...</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>/kaggle/input/tensorflow-great-barrier-reef/tr...</td>\n",
       "      <td>1</td>\n",
       "      <td>/kaggle/working/yolor_dataset/images/train/0-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>40258</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0-18</td>\n",
       "      <td>[{'x': 557, 'y': 213, 'width': 50, 'height': 32}]</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>../input/tensorflow-great-barrier-reef/train_i...</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>/kaggle/input/tensorflow-great-barrier-reef/tr...</td>\n",
       "      <td>1</td>\n",
       "      <td>/kaggle/working/yolor_dataset/images/train/0-1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    video_id  sequence  video_frame  sequence_frame image_id  \\\n",
       "16         0     40258           16              16     0-16   \n",
       "17         0     40258           17              17     0-17   \n",
       "18         0     40258           18              18     0-18   \n",
       "\n",
       "                                          annotations  n_annotations  \\\n",
       "16  [{'x': 559, 'y': 213, 'width': 50, 'height': 32}]              1   \n",
       "17  [{'x': 558, 'y': 213, 'width': 50, 'height': 32}]              1   \n",
       "18  [{'x': 557, 'y': 213, 'width': 50, 'height': 32}]              1   \n",
       "\n",
       "    has_annotations                                         image_path  \\\n",
       "16             True  ../input/tensorflow-great-barrier-reef/train_i...   \n",
       "17             True  ../input/tensorflow-great-barrier-reef/train_i...   \n",
       "18             True  ../input/tensorflow-great-barrier-reef/train_i...   \n",
       "\n",
       "    subsequence_id  is_train  \\\n",
       "16               2      True   \n",
       "17               2      True   \n",
       "18               2      True   \n",
       "\n",
       "                                                 path  num_bbox  \\\n",
       "16  /kaggle/input/tensorflow-great-barrier-reef/tr...         1   \n",
       "17  /kaggle/input/tensorflow-great-barrier-reef/tr...         1   \n",
       "18  /kaggle/input/tensorflow-great-barrier-reef/tr...         1   \n",
       "\n",
       "                                             new_path  \n",
       "16  /kaggle/working/yolor_dataset/images/train/0-1...  \n",
       "17  /kaggle/working/yolor_dataset/images/train/0-1...  \n",
       "18  /kaggle/working/yolor_dataset/images/train/0-1...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0022eadf",
   "metadata": {
    "papermill": {
     "duration": 0.036669,
     "end_time": "2022-01-06T15:52:38.076612",
     "exception": false,
     "start_time": "2022-01-06T15:52:38.039943",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Create yolor file structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7796de5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-06T15:52:38.159432Z",
     "iopub.status.busy": "2022-01-06T15:52:38.158323Z",
     "iopub.status.idle": "2022-01-06T15:52:38.164558Z",
     "shell.execute_reply": "2022-01-06T15:52:38.163939Z",
     "shell.execute_reply.started": "2022-01-06T13:46:01.366900Z"
    },
    "papermill": {
     "duration": 0.049953,
     "end_time": "2022-01-06T15:52:38.164721",
     "exception": false,
     "start_time": "2022-01-06T15:52:38.114768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory structure yor YoloR created\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(f\"{HOME_DIR}/yolor_dataset/images/train\")\n",
    "os.makedirs(f\"{HOME_DIR}/yolor_dataset/images/valid\")\n",
    "os.makedirs(f\"{HOME_DIR}/yolor_dataset/labels/train\")\n",
    "os.makedirs(f\"{HOME_DIR}/yolor_dataset/labels/valid\")\n",
    "print(f\"Directory structure yor YoloR created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39b0843c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-06T15:52:38.247058Z",
     "iopub.status.busy": "2022-01-06T15:52:38.245714Z",
     "iopub.status.idle": "2022-01-06T15:53:41.373617Z",
     "shell.execute_reply": "2022-01-06T15:53:41.374959Z",
     "shell.execute_reply.started": "2022-01-06T13:46:01.376925Z"
    },
    "papermill": {
     "duration": 63.17266,
     "end_time": "2022-01-06T15:53:41.375264",
     "exception": false,
     "start_time": "2022-01-06T15:52:38.202604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4919/4919 [01:03<00:00, 77.95it/s]\n"
     ]
    }
   ],
   "source": [
    "def copy_file(row):\n",
    "  copyfile(row.path, row.new_path)\n",
    "\n",
    "_ = df.progress_apply(lambda row: copy_file(row), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3bcf82",
   "metadata": {
    "papermill": {
     "duration": 2.012021,
     "end_time": "2022-01-06T15:53:43.738656",
     "exception": false,
     "start_time": "2022-01-06T15:53:41.726635",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cf63dc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-06T15:53:44.198870Z",
     "iopub.status.busy": "2022-01-06T15:53:44.197814Z",
     "iopub.status.idle": "2022-01-06T15:53:46.452165Z",
     "shell.execute_reply": "2022-01-06T15:53:46.450448Z",
     "shell.execute_reply.started": "2022-01-06T13:46:56.862325Z"
    },
    "papermill": {
     "duration": 2.488161,
     "end_time": "2022-01-06T15:53:46.452330",
     "exception": false,
     "start_time": "2022-01-06T15:53:43.964169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4919it [00:02, 2194.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotations in YoloR format for all images created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "IMG_WIDTH, IMG_HEIGHT = 1280, 720\n",
    "\n",
    "def get_yolo_format_bbox(img_w, img_h, box):\n",
    "    w = box['width'] \n",
    "    h = box['height']\n",
    "    \n",
    "    if bbox['x'] + bbox['width'] > 1280:\n",
    "        w = 1280 - bbox['x'] \n",
    "    if bbox['y'] + bbox['height'] > 720:\n",
    "        h = 720 - bbox['y'] \n",
    "        \n",
    "    xc = box['x'] + int(np.round(w/2))\n",
    "    yc = box['y'] + int(np.round(h/2)) \n",
    "\n",
    "    return [xc/img_w, yc/img_h, w/img_w, h/img_h]\n",
    "    \n",
    "\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    annotations = ast.literal_eval(row.annotations)\n",
    "    bboxes = []\n",
    "    for bbox in annotations:\n",
    "        bbox = get_yolo_format_bbox(IMG_WIDTH, IMG_HEIGHT, bbox)\n",
    "        bboxes.append(bbox)\n",
    "        \n",
    "    if row.is_train:\n",
    "        file_name = f\"{HOME_DIR}/yolor_dataset/labels/train/{row.image_id}.txt\"\n",
    "        os.makedirs(os.path.dirname(file_name), exist_ok=True)\n",
    "    else:\n",
    "        file_name = f\"{HOME_DIR}/yolor_dataset/labels/valid/{row.image_id}.txt\"\n",
    "        os.makedirs(os.path.dirname(file_name), exist_ok=True)\n",
    "        \n",
    "    with open(file_name, 'w') as f:\n",
    "        for i, bbox in enumerate(bboxes):\n",
    "            label = 0\n",
    "            bbox = [label]+bbox\n",
    "            bbox = [str(i) for i in bbox]\n",
    "            bbox = ' '.join(bbox)\n",
    "            f.write(bbox)\n",
    "            f.write('\\n')\n",
    "                \n",
    "print(\"Annotations in YoloR format for all images created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1dbfd1",
   "metadata": {
    "papermill": {
     "duration": 0.229187,
     "end_time": "2022-01-06T15:53:46.907952",
     "exception": false,
     "start_time": "2022-01-06T15:53:46.678765",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Create dataset configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed375e66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-06T15:53:47.373587Z",
     "iopub.status.busy": "2022-01-06T15:53:47.372702Z",
     "iopub.status.idle": "2022-01-06T15:53:47.376426Z",
     "shell.execute_reply": "2022-01-06T15:53:47.377011Z",
     "shell.execute_reply.started": "2022-01-06T13:46:58.519904Z"
    },
    "papermill": {
     "duration": 0.240283,
     "end_time": "2022-01-06T15:53:47.377186",
     "exception": false,
     "start_time": "2022-01-06T15:53:47.136903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset configuration file for YoloR created\n"
     ]
    }
   ],
   "source": [
    "data_yaml = dict(\n",
    "    train = f'{HOME_DIR}/yolor_dataset/images/train',\n",
    "    val = f'{HOME_DIR}/yolor_dataset/images/valid',\n",
    "    nc = 1,\n",
    "    names = ['sf']\n",
    ")\n",
    "\n",
    "\n",
    "with open(f'{HOME_DIR}/YoloR-data.yaml', 'w') as outfile:\n",
    "    yaml.dump(data_yaml, outfile, default_flow_style=True)\n",
    "\n",
    "print(f'Dataset configuration file for YoloR created')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53f044e",
   "metadata": {
    "papermill": {
     "duration": 0.220053,
     "end_time": "2022-01-06T15:53:47.826616",
     "exception": false,
     "start_time": "2022-01-06T15:53:47.606563",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Install YoloR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e53626f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-06T15:53:48.278137Z",
     "iopub.status.busy": "2022-01-06T15:53:48.277274Z",
     "iopub.status.idle": "2022-01-06T15:53:50.547645Z",
     "shell.execute_reply": "2022-01-06T15:53:50.546428Z",
     "shell.execute_reply.started": "2022-01-06T13:46:58.528008Z"
    },
    "papermill": {
     "duration": 2.496233,
     "end_time": "2022-01-06T15:53:50.547785",
     "exception": false,
     "start_time": "2022-01-06T15:53:48.051552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolor'...\r\n",
      "remote: Enumerating objects: 489, done.\u001b[K\r\n",
      "remote: Total 489 (delta 0), reused 0 (delta 0), pack-reused 489\u001b[K\r\n",
      "Receiving objects: 100% (489/489), 3.42 MiB | 5.81 MiB/s, done.\r\n",
      "Resolving deltas: 100% (225/225), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/WongKinYiu/yolor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00f76abe",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-01-06T15:53:51.020253Z",
     "iopub.status.busy": "2022-01-06T15:53:51.019250Z",
     "iopub.status.idle": "2022-01-06T15:55:42.219489Z",
     "shell.execute_reply": "2022-01-06T15:55:42.218095Z",
     "shell.execute_reply.started": "2022-01-06T13:46:59.804457Z"
    },
    "papermill": {
     "duration": 111.441453,
     "end_time": "2022-01-06T15:55:42.219816",
     "exception": false,
     "start_time": "2022-01-06T15:53:50.778363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n",
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.7/site-packages (0.12.7)\r\n",
      "Collecting wandb\r\n",
      "  Downloading wandb-0.12.9-py2.py3-none-any.whl (1.7 MB)\r\n",
      "     |████████████████████████████████| 1.7 MB 17 kB/s             \r\n",
      "\u001b[?25hRequirement already satisfied: pathtools in /opt/conda/lib/python3.7/site-packages (from wandb) (0.1.2)\r\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from wandb) (6.0)\r\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.16.0)\r\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.5.0)\r\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.1.24)\r\n",
      "Requirement already satisfied: yaspin>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.1.0)\r\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (0.4.0)\r\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.25.1)\r\n",
      "Requirement already satisfied: subprocess32>=3.5.3 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.5.4)\r\n",
      "Requirement already satisfied: configparser>=3.8.1 in /opt/conda/lib/python3.7/site-packages (from wandb) (5.1.0)\r\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.19.1)\r\n",
      "Requirement already satisfied: promise<3,>=2.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.3)\r\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (5.8.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.8.0)\r\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.0.8)\r\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (8.0.3)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (4.8.2)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb) (3.10.0.2)\r\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb) (4.0.9)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.26.7)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.10)\r\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (4.0.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\r\n",
      "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from yaspin>=1.0.0->wandb) (1.1.0)\r\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (3.0.5)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (3.6.0)\r\n",
      "Installing collected packages: wandb\r\n",
      "  Attempting uninstall: wandb\r\n",
      "    Found existing installation: wandb 0.12.7\r\n",
      "    Uninstalling wandb-0.12.7:\r\n",
      "      Successfully uninstalled wandb-0.12.7\r\n",
      "Successfully installed wandb-0.12.9\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision --upgrade -q\n",
    "!pip install wandb --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c51e795",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-01-06T15:55:42.895308Z",
     "iopub.status.busy": "2022-01-06T15:55:42.894316Z",
     "iopub.status.idle": "2022-01-06T15:57:05.914720Z",
     "shell.execute_reply": "2022-01-06T15:57:05.914181Z",
     "shell.execute_reply.started": "2022-01-06T13:48:25.702236Z"
    },
    "papermill": {
     "duration": 83.268649,
     "end_time": "2022-01-06T15:57:05.914883",
     "exception": false,
     "start_time": "2022-01-06T15:55:42.646234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/yolor\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "fastai 2.5.3 requires torchvision>=0.8.2, but you have torchvision 0.8.1 which is incompatible.\u001b[0m\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "%cd yolor\n",
    "!pip install -qr requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d70405e2",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-01-06T15:57:06.894375Z",
     "iopub.status.busy": "2022-01-06T15:57:06.890165Z",
     "iopub.status.idle": "2022-01-06T15:58:25.183122Z",
     "shell.execute_reply": "2022-01-06T15:58:25.182529Z",
     "shell.execute_reply.started": "2022-01-06T13:49:23.895563Z"
    },
    "papermill": {
     "duration": 78.543051,
     "end_time": "2022-01-06T15:58:25.183292",
     "exception": false,
     "start_time": "2022-01-06T15:57:06.640241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n",
      "Cloning into 'mish-cuda'...\r\n",
      "remote: Enumerating objects: 195, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (88/88), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (75/75), done.\u001b[K\r\n",
      "remote: Total 195 (delta 7), reused 79 (delta 3), pack-reused 107\u001b[K\r\n",
      "Receiving objects: 100% (195/195), 208.77 KiB | 869.00 KiB/s, done.\r\n",
      "Resolving deltas: 100% (56/56), done.\r\n",
      "/kaggle/working/mish-cuda\n",
      "HEAD is now at 6f38976 Update README.md\r\n",
      "/opt/conda/lib/python3.7/distutils/extension.py:131: UserWarning: Unknown Extension options: 'headers'\r\n",
      "  warnings.warn(msg)\r\n",
      "running build\r\n",
      "running build_py\r\n",
      "creating build\r\n",
      "creating build/lib.linux-x86_64-3.7\r\n",
      "creating build/lib.linux-x86_64-3.7/mish_cuda\r\n",
      "copying src/mish_cuda/__init__.py -> build/lib.linux-x86_64-3.7/mish_cuda\r\n",
      "running egg_info\r\n",
      "creating src/mish_cuda.egg-info\r\n",
      "writing src/mish_cuda.egg-info/PKG-INFO\r\n",
      "writing dependency_links to src/mish_cuda.egg-info/dependency_links.txt\r\n",
      "writing requirements to src/mish_cuda.egg-info/requires.txt\r\n",
      "writing top-level names to src/mish_cuda.egg-info/top_level.txt\r\n",
      "writing manifest file 'src/mish_cuda.egg-info/SOURCES.txt'\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/utils/cpp_extension.py:339: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\r\n",
      "  warnings.warn(msg.format('we could not find ninja.'))\r\n",
      "adding license file 'LICENSE'\r\n",
      "writing manifest file 'src/mish_cuda.egg-info/SOURCES.txt'\r\n",
      "running build_ext\r\n",
      "building 'mish_cuda._C' extension\r\n",
      "creating build/temp.linux-x86_64-3.7\r\n",
      "creating build/temp.linux-x86_64-3.7/csrc\r\n",
      "creating build/temp.linux-x86_64-3.7/csrc/cpu\r\n",
      "creating build/temp.linux-x86_64-3.7/csrc/cuda\r\n",
      "gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/opt/conda/lib/python3.7/site-packages/torch/include -I/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.7/site-packages/torch/include/TH -I/opt/conda/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.7m -c csrc/cpu/mish_cpu.cpp -o build/temp.linux-x86_64-3.7/csrc/cpu/mish_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\r\n",
      "\u001b[01m\u001b[Kcc1plus:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcommand line option ‘\u001b[01m\u001b[K-Wstrict-prototypes\u001b[m\u001b[K’ is valid for C/ObjC but not for C++\r\n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Parallel.h:149\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/torch/include/ATen/CPUApplyUtils.h:3\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[Kcsrc/cpu/mish_cpu.cpp:3\u001b[m\u001b[K:\r\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/torch/include/ATen/ParallelOpenMP.h:84:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring #pragma omp parallel [\u001b[01;35m\u001b[K-Wunknown-pragmas\u001b[m\u001b[K]\r\n",
      "   84 | #pragma omp parallel for if ((end - begin) >= grain_size)\r\n",
      "      | \r\n",
      "gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/opt/conda/lib/python3.7/site-packages/torch/include -I/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.7/site-packages/torch/include/TH -I/opt/conda/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.7m -c csrc/cuda/mish_cuda.cpp -o build/temp.linux-x86_64-3.7/csrc/cuda/mish_cuda.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\r\n",
      "\u001b[01m\u001b[Kcc1plus:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcommand line option ‘\u001b[01m\u001b[K-Wstrict-prototypes\u001b[m\u001b[K’ is valid for C/ObjC but not for C++\r\n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Parallel.h:149\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/utils.h:3\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:12\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[Kcsrc/cuda/mish_cuda.cpp:2\u001b[m\u001b[K:\r\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/torch/include/ATen/ParallelOpenMP.h:84:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring #pragma omp parallel [\u001b[01;35m\u001b[K-Wunknown-pragmas\u001b[m\u001b[K]\r\n",
      "   84 | #pragma omp parallel for if ((end - begin) >= grain_size)\r\n",
      "      | \r\n",
      "/usr/local/cuda/bin/nvcc -I/opt/conda/lib/python3.7/site-packages/torch/include -I/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.7/site-packages/torch/include/TH -I/opt/conda/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.7m -c csrc/cuda/mish_kernel.cu -o build/temp.linux-x86_64-3.7/csrc/cuda/mish_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' --expt-extended-lambda -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++14\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/boxing/impl/boxing.h(100): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/op_registration/op_whitelist.h(39): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/boxing/impl/boxing.h(100): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/op_registration/op_whitelist.h(39): warning: integer conversion resulted in a change of sign\r\n",
      "\r\n",
      "g++ -pthread -shared -B /opt/conda/compiler_compat -L/opt/conda/lib -Wl,-rpath=/opt/conda/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.7/csrc/cpu/mish_cpu.o build/temp.linux-x86_64-3.7/csrc/cuda/mish_cuda.o build/temp.linux-x86_64-3.7/csrc/cuda/mish_kernel.o -L/opt/conda/lib/python3.7/site-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.7/mish_cuda/_C.cpython-37m-x86_64-linux-gnu.so\r\n",
      "running install\r\n",
      "/opt/conda/lib/python3.7/site-packages/setuptools/command/install.py:37: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\r\n",
      "  setuptools.SetuptoolsDeprecationWarning,\r\n",
      "/opt/conda/lib/python3.7/site-packages/setuptools/command/easy_install.py:159: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\r\n",
      "  EasyInstallDeprecationWarning,\r\n",
      "running bdist_egg\r\n",
      "installing library code to build/bdist.linux-x86_64/egg\r\n",
      "running install_lib\r\n",
      "creating build/bdist.linux-x86_64\r\n",
      "creating build/bdist.linux-x86_64/egg\r\n",
      "creating build/bdist.linux-x86_64/egg/mish_cuda\r\n",
      "copying build/lib.linux-x86_64-3.7/mish_cuda/__init__.py -> build/bdist.linux-x86_64/egg/mish_cuda\r\n",
      "copying build/lib.linux-x86_64-3.7/mish_cuda/_C.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/mish_cuda\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/mish_cuda/__init__.py to __init__.cpython-37.pyc\r\n",
      "creating stub loader for mish_cuda/_C.cpython-37m-x86_64-linux-gnu.so\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/mish_cuda/_C.py to _C.cpython-37.pyc\r\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\r\n",
      "copying src/mish_cuda.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\r\n",
      "copying src/mish_cuda.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\r\n",
      "copying src/mish_cuda.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\r\n",
      "copying src/mish_cuda.egg-info/not-zip-safe -> build/bdist.linux-x86_64/egg/EGG-INFO\r\n",
      "copying src/mish_cuda.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\r\n",
      "copying src/mish_cuda.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\r\n",
      "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\r\n",
      "creating dist\r\n",
      "creating 'dist/mish_cuda-0.0.3-py3.7-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\r\n",
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\r\n",
      "Processing mish_cuda-0.0.3-py3.7-linux-x86_64.egg\r\n",
      "creating /opt/conda/lib/python3.7/site-packages/mish_cuda-0.0.3-py3.7-linux-x86_64.egg\r\n",
      "Extracting mish_cuda-0.0.3-py3.7-linux-x86_64.egg to /opt/conda/lib/python3.7/site-packages\r\n",
      "Adding mish-cuda 0.0.3 to easy-install.pth file\r\n",
      "\r\n",
      "Installed /opt/conda/lib/python3.7/site-packages/mish_cuda-0.0.3-py3.7-linux-x86_64.egg\r\n",
      "Processing dependencies for mish-cuda==0.0.3\r\n",
      "Searching for torch==1.7.0\r\n",
      "Best match: torch 1.7.0\r\n",
      "Adding torch 1.7.0 to easy-install.pth file\r\n",
      "Installing convert-caffe2-to-onnx script to /opt/conda/bin\r\n",
      "Installing convert-onnx-to-caffe2 script to /opt/conda/bin\r\n",
      "\r\n",
      "Using /opt/conda/lib/python3.7/site-packages\r\n",
      "Searching for dataclasses==0.8\r\n",
      "Best match: dataclasses 0.8\r\n",
      "Adding dataclasses 0.8 to easy-install.pth file\r\n",
      "\r\n",
      "Using /opt/conda/lib/python3.7/site-packages\r\n",
      "Searching for future==0.18.2\r\n",
      "Best match: future 0.18.2\r\n",
      "Adding future 0.18.2 to easy-install.pth file\r\n",
      "Installing futurize script to /opt/conda/bin\r\n",
      "Installing pasteurize script to /opt/conda/bin\r\n",
      "\r\n",
      "Using /opt/conda/lib/python3.7/site-packages\r\n",
      "Searching for typing-extensions==3.10.0.2\r\n",
      "Best match: typing-extensions 3.10.0.2\r\n",
      "Adding typing-extensions 3.10.0.2 to easy-install.pth file\r\n",
      "\r\n",
      "Using /opt/conda/lib/python3.7/site-packages\r\n",
      "Searching for numpy==1.19.5\r\n",
      "Best match: numpy 1.19.5\r\n",
      "Adding numpy 1.19.5 to easy-install.pth file\r\n",
      "Installing f2py script to /opt/conda/bin\r\n",
      "Installing f2py3 script to /opt/conda/bin\r\n",
      "Installing f2py3.7 script to /opt/conda/bin\r\n",
      "\r\n",
      "Using /opt/conda/lib/python3.7/site-packages\r\n",
      "Finished processing dependencies for mish-cuda==0.0.3\r\n",
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "!git clone https://github.com/JunnYu/mish-cuda\n",
    "%cd mish-cuda\n",
    "!git reset --hard 6f38976064cbcc4782f4212d7c0c5f6dd5e315a8\n",
    "!python setup.py build install\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "612065bf",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-01-06T15:58:26.228323Z",
     "iopub.status.busy": "2022-01-06T15:58:26.227214Z",
     "iopub.status.idle": "2022-01-06T15:58:40.631287Z",
     "shell.execute_reply": "2022-01-06T15:58:40.630699Z",
     "shell.execute_reply.started": "2022-01-06T13:50:22.537488Z"
    },
    "papermill": {
     "duration": 14.67953,
     "end_time": "2022-01-06T15:58:40.631479",
     "exception": false,
     "start_time": "2022-01-06T15:58:25.951949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'pytorch_wavelets'...\r\n",
      "remote: Enumerating objects: 972, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (136/136), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (91/91), done.\u001b[K\r\n",
      "remote: Total 972 (delta 75), reused 89 (delta 45), pack-reused 836\u001b[K\r\n",
      "Receiving objects: 100% (972/972), 6.80 MiB | 10.31 MiB/s, done.\r\n",
      "Resolving deltas: 100% (659/659), done.\r\n",
      "/kaggle/working/pytorch_wavelets\n",
      "Processing /kaggle/working/pytorch_wavelets\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from pytorch-wavelets==1.3.0) (1.19.5)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from pytorch-wavelets==1.3.0) (1.16.0)\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from pytorch-wavelets==1.3.0) (1.7.0)\r\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch->pytorch-wavelets==1.3.0) (0.8)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch->pytorch-wavelets==1.3.0) (3.10.0.2)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch->pytorch-wavelets==1.3.0) (0.18.2)\r\n",
      "Building wheels for collected packages: pytorch-wavelets\r\n",
      "  Building wheel for pytorch-wavelets (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pytorch-wavelets: filename=pytorch_wavelets-1.3.0-py3-none-any.whl size=54869 sha256=4e31b0cfc94bc5caae5e11a9c82da111ab1214cc32ce5709bf02e2e3ed1c24c6\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-zcr3clxn/wheels/4e/20/0e/1cc3e3dfdf491bfbbbf4504aa4b4b834d188ed23b0e892eef5\r\n",
      "Successfully built pytorch-wavelets\r\n",
      "Installing collected packages: pytorch-wavelets\r\n",
      "Successfully installed pytorch-wavelets-1.3.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n",
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/fbcotter/pytorch_wavelets\n",
    "%cd pytorch_wavelets\n",
    "!pip install .\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43c7263e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-06T15:58:41.663902Z",
     "iopub.status.busy": "2022-01-06T15:58:41.663007Z",
     "iopub.status.idle": "2022-01-06T15:58:56.871082Z",
     "shell.execute_reply": "2022-01-06T15:58:56.870164Z",
     "shell.execute_reply.started": "2022-01-06T13:50:32.356853Z"
    },
    "papermill": {
     "duration": 15.469501,
     "end_time": "2022-01-06T15:58:56.871239",
     "exception": false,
     "start_time": "2022-01-06T15:58:41.401738",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/yolor\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "100   408    0   408    0     0   1421      0 --:--:-- --:--:-- --:--:--  1421\r\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\r\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:04 --:--:--     0\r\n",
      "100  142M  100  142M    0     0  19.1M      0  0:00:07  0:00:07 --:--:-- 61.3M\r\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "100   408    0   408    0     0   1500      0 --:--:-- --:--:-- --:--:--  1500\r\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\r\n",
      "100  305M  100  305M    0     0  48.7M      0  0:00:06  0:00:06 --:--:-- 72.5M\r\n"
     ]
    }
   ],
   "source": [
    "%cd yolor\n",
    "!bash scripts/get_pretrain.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1240651c",
   "metadata": {
    "papermill": {
     "duration": 0.266718,
     "end_time": "2022-01-06T15:58:57.403143",
     "exception": false,
     "start_time": "2022-01-06T15:58:57.136425",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Weights and biases for logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1abde88f",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-01-06T15:58:57.961919Z",
     "iopub.status.busy": "2022-01-06T15:58:57.960902Z",
     "iopub.status.idle": "2022-01-06T15:59:00.823134Z",
     "shell.execute_reply": "2022-01-06T15:59:00.822553Z",
     "shell.execute_reply.started": "2022-01-06T13:50:37.729473Z"
    },
    "papermill": {
     "duration": 3.146827,
     "end_time": "2022-01-06T15:59:00.823288",
     "exception": false,
     "start_time": "2022-01-06T15:58:57.676461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publically.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mandreas_g\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "user_secrets = UserSecretsClient()\n",
    "wandb_api = user_secrets.get_secret(\"wandb_api\") \n",
    "wandb.login(key=wandb_api)\n",
    "wandb.login(anonymous='must')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9dda81",
   "metadata": {
    "papermill": {
     "duration": 0.269651,
     "end_time": "2022-01-06T15:59:01.364908",
     "exception": false,
     "start_time": "2022-01-06T15:59:01.095257",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "921f6815",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-06T15:59:02.270181Z",
     "iopub.status.busy": "2022-01-06T15:59:02.269240Z",
     "iopub.status.idle": "2022-01-06T15:59:02.275471Z",
     "shell.execute_reply": "2022-01-06T15:59:02.276516Z",
     "shell.execute_reply.started": "2022-01-06T13:50:38.992229Z"
    },
    "papermill": {
     "duration": 0.505992,
     "end_time": "2022-01-06T15:59:02.276777",
     "exception": false,
     "start_time": "2022-01-06T15:59:01.770785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@register_line_cell_magic\n",
    "def writetemplate(line, cell):\n",
    "    with open(line, 'w') as f:\n",
    "        f.write(cell.format(**globals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee6c5362",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-06T15:59:03.193961Z",
     "iopub.status.busy": "2022-01-06T15:59:03.182943Z",
     "iopub.status.idle": "2022-01-06T15:59:03.202242Z",
     "shell.execute_reply": "2022-01-06T15:59:03.201569Z",
     "shell.execute_reply.started": "2022-01-06T13:50:38.999826Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.389234,
     "end_time": "2022-01-06T15:59:03.202383",
     "exception": false,
     "start_time": "2022-01-06T15:59:02.813149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writetemplate /kaggle/working/yolor/cfg/yolor_pg.cfg\n",
    "\n",
    "\n",
    "[net]\n",
    "batch=64\n",
    "subdivisions=8\n",
    "width=1280\n",
    "height=1280\n",
    "channels=3\n",
    "momentum=0.949\n",
    "decay=0.0005\n",
    "angle=0\n",
    "saturation = 1.5\n",
    "exposure = 1.5\n",
    "hue=.1\n",
    "\n",
    "# learning_rate=0.00261\n",
    "learning_rate=0.01\n",
    "burn_in=1000\n",
    "max_batches = 500500\n",
    "policy=steps\n",
    "steps=400000,450000\n",
    "scales=.1,.1\n",
    "\n",
    "mosaic=1\n",
    "\n",
    "\n",
    "# ============ Backbone ============ #\n",
    "\n",
    "# Stem \n",
    "\n",
    "# P1\n",
    "\n",
    "# Downsample\n",
    "\n",
    "# 0\n",
    "[reorg]\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=64\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "\n",
    "# P2\n",
    "\n",
    "# Downsample\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=3\n",
    "stride=2\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "# Split\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=64\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[route]\n",
    "layers = -2\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=64\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "# Residual Block\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=64\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=64\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=64\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=64\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=64\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=64\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "# Transition first\n",
    "#\n",
    "#[convolutional]\n",
    "#batch_normalize=1\n",
    "#filters=64\n",
    "#size=1\n",
    "#stride=1\n",
    "#pad=1\n",
    "#activation=silu\n",
    "\n",
    "# Merge [-1, -(3k+3)]\n",
    "\n",
    "[route]\n",
    "layers = -1,-12\n",
    "\n",
    "# Transition last\n",
    "\n",
    "# 16 (previous+6+3k)\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "\n",
    "# P3\n",
    "\n",
    "# Downsample\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=3\n",
    "stride=2\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "# Split\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[route]\n",
    "layers = -2\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "# Residual Block\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "# Transition first\n",
    "#\n",
    "#[convolutional]\n",
    "#batch_normalize=1\n",
    "#filters=128\n",
    "#size=1\n",
    "#stride=1\n",
    "#pad=1\n",
    "#activation=silu\n",
    "\n",
    "# Merge [-1, -(3k+3)]\n",
    "\n",
    "[route]\n",
    "layers = -1,-24\n",
    "\n",
    "# Transition last\n",
    "\n",
    "# 43 (previous+6+3k)\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "\n",
    "# P4\n",
    "\n",
    "# Downsample\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=384\n",
    "size=3\n",
    "stride=2\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "# Split\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=192\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[route]\n",
    "layers = -2\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=192\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "# Residual Block\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=192\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=192\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=192\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=192\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=192\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=192\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=192\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=192\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=192\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=192\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=192\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=192\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=192\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=192\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "# Transition first\n",
    "#\n",
    "#[convolutional]\n",
    "#batch_normalize=1\n",
    "#filters=192\n",
    "#size=1\n",
    "#stride=1\n",
    "#pad=1\n",
    "#activation=silu\n",
    "\n",
    "# Merge [-1, -(3k+3)]\n",
    "\n",
    "[route]\n",
    "layers = -1,-24\n",
    "\n",
    "# Transition last\n",
    "\n",
    "# 70 (previous+6+3k)\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=384\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "\n",
    "# P5\n",
    "\n",
    "# Downsample\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=512\n",
    "size=3\n",
    "stride=2\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "# Split\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[route]\n",
    "layers = -2\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "# Residual Block\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "# Transition first\n",
    "#\n",
    "#[convolutional]\n",
    "#batch_normalize=1\n",
    "#filters=256\n",
    "#size=1\n",
    "#stride=1\n",
    "#pad=1\n",
    "#activation=silu\n",
    "\n",
    "# Merge [-1, -(3k+3)]\n",
    "\n",
    "[route]\n",
    "layers = -1,-12\n",
    "\n",
    "# Transition last\n",
    "\n",
    "# 85 (previous+6+3k)\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=512\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "\n",
    "# P6\n",
    "\n",
    "# Downsample\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=640\n",
    "size=3\n",
    "stride=2\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "# Split\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=320\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[route]\n",
    "layers = -2\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=320\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "# Residual Block\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=320\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=320\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=320\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=320\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=320\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=320\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[shortcut]\n",
    "from=-3\n",
    "activation=linear\n",
    "\n",
    "# Transition first\n",
    "#\n",
    "#[convolutional]\n",
    "#batch_normalize=1\n",
    "#filters=320\n",
    "#size=1\n",
    "#stride=1\n",
    "#pad=1\n",
    "#activation=silu\n",
    "\n",
    "# Merge [-1, -(3k+3)]\n",
    "\n",
    "[route]\n",
    "layers = -1,-12\n",
    "\n",
    "# Transition last\n",
    "\n",
    "# 100 (previous+6+3k)\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=640\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "# ============ End of Backbone ============ #\n",
    "\n",
    "# ============ Neck ============ #\n",
    "\n",
    "# CSPSPP\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=320\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[route]\n",
    "layers = -2\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=320\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=320\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=320\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "### SPP ###\n",
    "[maxpool]\n",
    "stride=1\n",
    "size=5\n",
    "\n",
    "[route]\n",
    "layers=-2\n",
    "\n",
    "[maxpool]\n",
    "stride=1\n",
    "size=9\n",
    "\n",
    "[route]\n",
    "layers=-4\n",
    "\n",
    "[maxpool]\n",
    "stride=1\n",
    "size=13\n",
    "\n",
    "[route]\n",
    "layers=-1,-3,-5,-6\n",
    "### End SPP ###\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=320\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=320\n",
    "activation=silu\n",
    "\n",
    "[route]\n",
    "layers = -1, -13\n",
    "\n",
    "# 115 (previous+6+5+2k)\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=320\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "# End of CSPSPP\n",
    "\n",
    "\n",
    "# FPN-5\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[upsample]\n",
    "stride=2\n",
    "\n",
    "[route]\n",
    "layers = 85\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[route]\n",
    "layers = -1, -3\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "# Split\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[route]\n",
    "layers = -2\n",
    "\n",
    "# Plain Block\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=256\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=256\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=256\n",
    "activation=silu\n",
    "\n",
    "# Merge [-1, -(2k+2)]\n",
    "\n",
    "[route]\n",
    "layers = -1, -8\n",
    "\n",
    "# Transition last\n",
    "\n",
    "# 131 (previous+6+4+2k)\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "\n",
    "# FPN-4\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=192\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[upsample]\n",
    "stride=2\n",
    "\n",
    "[route]\n",
    "layers = 70\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=192\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[route]\n",
    "layers = -1, -3\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=192\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "# Split\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=192\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[route]\n",
    "layers = -2\n",
    "\n",
    "# Plain Block\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=192\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=192\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=192\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=192\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=192\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=192\n",
    "activation=silu\n",
    "\n",
    "# Merge [-1, -(2k+2)]\n",
    "\n",
    "[route]\n",
    "layers = -1, -8\n",
    "\n",
    "# Transition last\n",
    "\n",
    "# 147 (previous+6+4+2k)\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=192\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "\n",
    "# FPN-3\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[upsample]\n",
    "stride=2\n",
    "\n",
    "[route]\n",
    "layers = 43\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[route]\n",
    "layers = -1, -3\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "# Split\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[route]\n",
    "layers = -2\n",
    "\n",
    "# Plain Block\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=128\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=128\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=128\n",
    "activation=silu\n",
    "\n",
    "# Merge [-1, -(2k+2)]\n",
    "\n",
    "[route]\n",
    "layers = -1, -8\n",
    "\n",
    "# Transition last\n",
    "\n",
    "# 163 (previous+6+4+2k)\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "\n",
    "# PAN-4\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=2\n",
    "pad=1\n",
    "filters=192\n",
    "activation=silu\n",
    "\n",
    "[route]\n",
    "layers = -1, 147\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=192\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "# Split\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=192\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[route]\n",
    "layers = -2\n",
    "\n",
    "# Plain Block\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=192\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=192\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=192\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=192\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=192\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=192\n",
    "activation=silu\n",
    "\n",
    "[route]\n",
    "layers = -1,-8\n",
    "\n",
    "# Transition last\n",
    "\n",
    "# 176 (previous+3+4+2k)\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=192\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "\n",
    "# PAN-5\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=2\n",
    "pad=1\n",
    "filters=256\n",
    "activation=silu\n",
    "\n",
    "[route]\n",
    "layers = -1, 131\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "# Split\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[route]\n",
    "layers = -2\n",
    "\n",
    "# Plain Block\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=256\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=256\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=256\n",
    "activation=silu\n",
    "\n",
    "[route]\n",
    "layers = -1,-8\n",
    "\n",
    "# Transition last\n",
    "\n",
    "# 189 (previous+3+4+2k)\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "\n",
    "# PAN-6\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=2\n",
    "pad=1\n",
    "filters=320\n",
    "activation=silu\n",
    "\n",
    "[route]\n",
    "layers = -1, 115\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=320\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "# Split\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=320\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[route]\n",
    "layers = -2\n",
    "\n",
    "# Plain Block\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=320\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=320\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=320\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=320\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=320\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=320\n",
    "activation=silu\n",
    "\n",
    "[route]\n",
    "layers = -1,-8\n",
    "\n",
    "# Transition last\n",
    "\n",
    "# 202 (previous+3+4+2k)\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=320\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "activation=silu\n",
    "\n",
    "# ============ End of Neck ============ #\n",
    "\n",
    "# 203\n",
    "[implicit_add]\n",
    "filters=256\n",
    "\n",
    "# 204\n",
    "[implicit_add]\n",
    "filters=384\n",
    "\n",
    "# 205\n",
    "[implicit_add]\n",
    "filters=512\n",
    "\n",
    "# 206\n",
    "[implicit_add]\n",
    "filters=640\n",
    "\n",
    "# 207\n",
    "[implicit_mul]\n",
    "filters=18\n",
    "\n",
    "# 208\n",
    "[implicit_mul]\n",
    "filters=18\n",
    "\n",
    "# 209\n",
    "[implicit_mul]\n",
    "filters=18\n",
    "\n",
    "# 210\n",
    "[implicit_mul]\n",
    "filters=18\n",
    "\n",
    "# ============ Head ============ #\n",
    "\n",
    "# YOLO-3\n",
    "\n",
    "[route]\n",
    "layers = 163\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=256\n",
    "activation=silu\n",
    "\n",
    "[shift_channels]\n",
    "from=203\n",
    "\n",
    "[convolutional]\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "filters=18\n",
    "activation=linear\n",
    "\n",
    "[control_channels]\n",
    "from=207\n",
    "\n",
    "[yolo]\n",
    "mask = 0,1,2\n",
    "anchors = 19,27,  44,40,  38,94,  96,68,  86,152,  180,137,  140,301,  303,264,  238,542,  436,615,  739,380,  925,792\n",
    "classes=1\n",
    "num=12\n",
    "jitter=.3\n",
    "ignore_thresh = .7\n",
    "truth_thresh = 1\n",
    "random=1\n",
    "scale_x_y = 1.05\n",
    "iou_thresh=0.213\n",
    "cls_normalizer=1.0\n",
    "iou_normalizer=0.07\n",
    "iou_loss=ciou\n",
    "nms_kind=greedynms\n",
    "beta_nms=0.6\n",
    "\n",
    "\n",
    "# YOLO-4\n",
    "\n",
    "[route]\n",
    "layers = 176\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=384\n",
    "activation=silu\n",
    "\n",
    "[shift_channels]\n",
    "from=204\n",
    "\n",
    "[convolutional]\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "filters=18\n",
    "activation=linear\n",
    "\n",
    "[control_channels]\n",
    "from=208\n",
    "\n",
    "[yolo]\n",
    "mask = 3,4,5\n",
    "anchors = 19,27,  44,40,  38,94,  96,68,  86,152,  180,137,  140,301,  303,264,  238,542,  436,615,  739,380,  925,792\n",
    "classes=1\n",
    "num=12\n",
    "jitter=.3\n",
    "ignore_thresh = .7\n",
    "truth_thresh = 1\n",
    "random=1\n",
    "scale_x_y = 1.05\n",
    "iou_thresh=0.213\n",
    "cls_normalizer=1.0\n",
    "iou_normalizer=0.07\n",
    "iou_loss=ciou\n",
    "nms_kind=greedynms\n",
    "beta_nms=0.6\n",
    "\n",
    "\n",
    "# YOLO-5\n",
    "\n",
    "[route]\n",
    "layers = 189\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=512\n",
    "activation=silu\n",
    "\n",
    "[shift_channels]\n",
    "from=205\n",
    "\n",
    "[convolutional]\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "filters=18\n",
    "activation=linear\n",
    "\n",
    "[control_channels]\n",
    "from=209\n",
    "\n",
    "[yolo]\n",
    "mask = 6,7,8\n",
    "anchors = 19,27,  44,40,  38,94,  96,68,  86,152,  180,137,  140,301,  303,264,  238,542,  436,615,  739,380,  925,792\n",
    "classes=1\n",
    "num=12\n",
    "jitter=.3\n",
    "ignore_thresh = .7\n",
    "truth_thresh = 1\n",
    "random=1\n",
    "scale_x_y = 1.05\n",
    "iou_thresh=0.213\n",
    "cls_normalizer=1.0\n",
    "iou_normalizer=0.07\n",
    "iou_loss=ciou\n",
    "nms_kind=greedynms\n",
    "beta_nms=0.6\n",
    "\n",
    "\n",
    "# YOLO-6\n",
    "\n",
    "[route]\n",
    "layers = 202\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=640\n",
    "activation=silu\n",
    "\n",
    "[shift_channels]\n",
    "from=206\n",
    "\n",
    "[convolutional]\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "filters=18\n",
    "activation=linear\n",
    "\n",
    "[control_channels]\n",
    "from=210\n",
    "\n",
    "[yolo]\n",
    "mask = 9,10,11\n",
    "anchors = 19,27,  44,40,  38,94,  96,68,  86,152,  180,137,  140,301,  303,264,  238,542,  436,615,  739,380,  925,792\n",
    "classes=1\n",
    "num=12\n",
    "jitter=.3\n",
    "ignore_thresh = .7\n",
    "truth_thresh = 1\n",
    "random=1\n",
    "scale_x_y = 1.05\n",
    "iou_thresh=0.213\n",
    "cls_normalizer=1.0\n",
    "iou_normalizer=0.07\n",
    "iou_loss=ciou\n",
    "nms_kind=greedynms\n",
    "# beta_nms=0.6\n",
    "beta_nms=0.45\n",
    "\n",
    "# ============ End of Head ============ #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a199f004",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-06T15:59:03.768417Z",
     "iopub.status.busy": "2022-01-06T15:59:03.767562Z",
     "iopub.status.idle": "2022-01-06T15:59:03.772296Z",
     "shell.execute_reply": "2022-01-06T15:59:03.771656Z",
     "shell.execute_reply.started": "2022-01-06T13:50:39.019120Z"
    },
    "papermill": {
     "duration": 0.283254,
     "end_time": "2022-01-06T15:59:03.772440",
     "exception": false,
     "start_time": "2022-01-06T15:59:03.489186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writetemplate /kaggle/working/yolor/data/coco.yaml\n",
    "\n",
    "nc: 1\n",
    "names: ['starfish',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6eb67ba6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-06T15:59:04.321076Z",
     "iopub.status.busy": "2022-01-06T15:59:04.319980Z",
     "iopub.status.idle": "2022-01-06T15:59:04.322436Z",
     "shell.execute_reply": "2022-01-06T15:59:04.323086Z",
     "shell.execute_reply.started": "2022-01-06T13:50:39.031404Z"
    },
    "papermill": {
     "duration": 0.282365,
     "end_time": "2022-01-06T15:59:04.323270",
     "exception": false,
     "start_time": "2022-01-06T15:59:04.040905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writetemplate /kaggle/working/yolor/data/coco.names\n",
    "\n",
    "starfish"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38ede82",
   "metadata": {},
   "source": [
    "### Set hyperparameters (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dbaa0fab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-06T15:59:04.874470Z",
     "iopub.status.busy": "2022-01-06T15:59:04.873523Z",
     "iopub.status.idle": "2022-01-06T15:59:04.876889Z",
     "shell.execute_reply": "2022-01-06T15:59:04.877452Z",
     "shell.execute_reply.started": "2022-01-06T13:50:39.040688Z"
    },
    "papermill": {
     "duration": 0.280696,
     "end_time": "2022-01-06T15:59:04.877622",
     "exception": false,
     "start_time": "2022-01-06T15:59:04.596926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writetemplate /kaggle/working/hyp-yolor.yaml\n",
    "\n",
    "lr0: 0.01  # initial learning rate (SGD=1E-2, Adam=1E-3)\n",
    "lrf: 0.2  # final OneCycleLR learning rate (lr0 * lrf)\n",
    "momentum: 0.937  # SGD momentum/Adam beta1\n",
    "weight_decay: 0.0005  # optimizer weight decay 5e-4\n",
    "warmup_epochs: 3.0  # warmup epochs (fractions ok)\n",
    "warmup_momentum: 0.8  # warmup initial momentum\n",
    "warmup_bias_lr: 0.1  # warmup initial bias lr\n",
    "box: 0.05  # box loss gain\n",
    "cls: 0.5  # cls loss gain\n",
    "cls_pw: 1.0  # cls BCELoss positive_weight\n",
    "obj: 1.0  # obj loss gain (scale with pixels)\n",
    "obj_pw: 1.0  # obj BCELoss positive_weight\n",
    "iou_t: 0.20  # IoU training threshold\n",
    "anchor_t: 4.0  # anchor-multiple threshold\n",
    "# anchors: 3  # anchors per output layer (0 to ignore)\n",
    "fl_gamma: 0.0  # focal loss gamma (efficientDet default gamma=1.5)\n",
    "hsv_h: 0.015  # image HSV-Hue augmentation (fraction)\n",
    "hsv_s: 0.7  # image HSV-Saturation augmentation (fraction)\n",
    "hsv_v: 0.4  # image HSV-Value augmentation (fraction)\n",
    "degrees: 0.0  # image rotation (+/- deg)\n",
    "translate: 0.5  # image translation (+/- fraction)\n",
    "scale: 0.5  # image scale (+/- gain)\n",
    "shear: 0.0  # image shear (+/- deg)\n",
    "perspective: 0.0  # image perspective (+/- fraction), range 0-0.001\n",
    "flipud: 0.0  # image flip up-down (probability)\n",
    "fliplr: 0.5  # image flip left-right (probability)\n",
    "mosaic: 1.0  # image mosaic (probability)\n",
    "mixup: 0.0  # image mixup (probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4006b503",
   "metadata": {
    "papermill": {
     "duration": 0.273555,
     "end_time": "2022-01-06T15:59:05.426399",
     "exception": false,
     "start_time": "2022-01-06T15:59:05.152844",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30b67fbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-06T15:59:05.975244Z",
     "iopub.status.busy": "2022-01-06T15:59:05.974413Z",
     "iopub.status.idle": "2022-01-06T15:59:05.978252Z",
     "shell.execute_reply": "2022-01-06T15:59:05.978761Z",
     "shell.execute_reply.started": "2022-01-06T13:51:40.417160Z"
    },
    "papermill": {
     "duration": 0.280189,
     "end_time": "2022-01-06T15:59:05.978912",
     "exception": false,
     "start_time": "2022-01-06T15:59:05.698723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/yolor\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2dd909cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-06T15:59:11.849107Z",
     "iopub.status.busy": "2022-01-06T15:59:11.848118Z",
     "iopub.status.idle": "2022-01-06T23:35:36.812728Z",
     "shell.execute_reply": "2022-01-06T23:35:36.811899Z",
     "shell.execute_reply.started": "2022-01-06T13:55:52.842057Z"
    },
    "papermill": {
     "duration": 27385.418023,
     "end_time": "2022-01-06T23:35:36.812882",
     "exception": false,
     "start_time": "2022-01-06T15:59:11.394859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transferred 862/862 items from ./best_overall.pt\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mandreas_g\u001b[0m (use `wandb login --relogin` to force relogin)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.9\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Resuming run \u001b[33myolor_p6\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/andreas_g/YOLOR\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/andreas_g/YOLOR/runs/3gfivotm\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /kaggle/working/yolor/wandb/run-20220106_155932-3gfivotm\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 485... (failed 1). Press ctrl-c to abort syncing.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP_0.5 ▅▂▄▄▅▇▁▃▆▄▄▂▄█▅▆▆▅▇█▇▆▆▇▆▄▃▄▇▇▆\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   metrics/mAP_0.5:0.95 ▅▃▅▃▅▅▂▄▄▁▃▂▃▇▄▅▅▄▇▅▅▃▅▆▄▅▃▄▇█▆\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/precision ▇▁▆▆▇▄▃▄▃▃▄▅▆▆█▆▅██▇▆▇▇▆▆▅▃▆▇█▇\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         metrics/recall ▄▄▅▅▆█▄▅▃▆▄▆▂▆▅▃▄▄▅▃▃▃▃▃▄▃▂▁▁▃▁\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train/box_loss ▅█▇▇▇▆▅▆▅▄▄▄▄▃▃▃▃▂▃▃▃▃▂▂▂▂▂▁▂▁▁\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train/cls_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train/obj_loss ▇█▇▇▇▆▆▅▄▄▄▄▅▃▄▃▃▄▄▂▃▃▄▂▂▂▁▁▁▁▁\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           val/box_loss ▃▁▁▄▇▂▅▃▆▆▃▆▅▅▅█▇█▇▆▇▇▅▆▇▆▅▇▇▇█\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           val/cls_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           val/obj_loss ▃▁▃▁▄▃▄▄▃▄▅▅▇▅▄▅▇▄▄▇▆▆▇▇▄▇▇▇█▇▇\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr0 ▃██▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr1 ▃██▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr2 ▃██▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP_0.5 0.46324\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   metrics/mAP_0.5:0.95 0.25755\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/precision 0.95075\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         metrics/recall 0.22447\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train/box_loss 0.01137\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train/cls_loss 0.0\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train/obj_loss 0.00253\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           val/box_loss 0.02391\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           val/cls_loss 0.0\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           val/obj_loss 0.02237\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr0 0.00207\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr1 0.00207\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr2 0.00207\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 3 W&B file(s), 2 media file(s), 0 artifact file(s) and 0 other file(s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33myolor_p6\u001b[0m: \u001b[34mhttps://wandb.ai/andreas_g/YOLOR/runs/3gfivotm\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: ./wandb/run-20220106_155932-3gfivotm/logs/debug.log\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \r\n"
     ]
    }
   ],
   "source": [
    "!python train.py \\\n",
    " --batch-size 4 \\\n",
    " --img 1280 768 \\\n",
    " --data '{HOME_DIR}/YoloR-data.yaml' \\\n",
    " --cfg './cfg/yolor_p6.cfg' \\\n",
    " --weights './yolor_p6.pt' \\\n",
    " --device 0 \\\n",
    " --name yolor_p6 \\\n",
    " --hyp '/kaggle/working/hyp-yolor.yaml' \\\n",
    " --epochs 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fe5b2e",
   "metadata": {
    "papermill": {
     "duration": 13.277739,
     "end_time": "2022-01-06T23:36:03.618693",
     "exception": false,
     "start_time": "2022-01-06T23:35:50.340954",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a149366",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-06T23:36:57.223641Z",
     "iopub.status.busy": "2022-01-06T23:36:57.222923Z",
     "iopub.status.idle": "2022-01-06T23:36:57.761321Z",
     "shell.execute_reply": "2022-01-06T23:36:57.760673Z",
     "shell.execute_reply.started": "2022-01-06T13:50:39.158826Z"
    },
    "papermill": {
     "duration": 14.198826,
     "end_time": "2022-01-06T23:36:57.761470",
     "exception": false,
     "start_time": "2022-01-06T23:36:43.562644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 28.44it/s]\n"
     ]
    }
   ],
   "source": [
    "INFER_PATH = f\"{HOME_DIR}/yolor_dataset/infer\"\n",
    "os.makedirs(INFER_PATH)\n",
    "\n",
    "df_infer = df.query(\"~is_train and num_bbox > 4\").sample(15)\n",
    "\n",
    "def copy_file(row):\n",
    "    new_location = INFER_PATH + '/' + row.image_id + '.jpg'\n",
    "    copyfile(row.path, new_location)\n",
    "\n",
    "_ = df_infer.progress_apply(lambda row: copy_file(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "003ca606",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-06T23:37:24.999431Z",
     "iopub.status.busy": "2022-01-06T23:37:24.998539Z",
     "iopub.status.idle": "2022-01-06T23:37:34.186199Z",
     "shell.execute_reply": "2022-01-06T23:37:34.185666Z",
     "shell.execute_reply.started": "2022-01-06T13:50:39.160540Z"
    },
    "papermill": {
     "duration": 22.855072,
     "end_time": "2022-01-06T23:37:34.186341",
     "exception": false,
     "start_time": "2022-01-06T23:37:11.331269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(agnostic_nms=False, augment=False, cfg='./cfg/yolor_p6.cfg', classes=None, conf_thres=0.05, device='0', img_size=1280, iou_thres=0.5, names='data/coco.names', output='inference/output', save_txt=False, source='/kaggle/working/yolor_dataset/infer', update=False, view_img=False, weights=['/kaggle/working/yolor/runs/train/yolor_p6/weights/best_overall.pt'])\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"detect.py\", line 186, in <module>\r\n",
      "    detect()\r\n",
      "  File \"detect.py\", line 44, in detect\r\n",
      "    model.load_state_dict(torch.load(weights[0], map_location=device)['model'])\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/serialization.py\", line 581, in load\r\n",
      "    with _open_file_like(f, 'rb') as opened_file:\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/serialization.py\", line 230, in _open_file_like\r\n",
      "    return _open_file(name_or_buffer, mode)\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/serialization.py\", line 211, in __init__\r\n",
      "    super(_open_file, self).__init__(open(name, mode))\r\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/kaggle/working/yolor/runs/train/yolor_p6/weights/best_overall.pt'\r\n"
     ]
    }
   ],
   "source": [
    "!python detect.py \\\n",
    "    --source {INFER_PATH} \\\n",
    "    --cfg ./cfg/yolor_p6.cfg \\\n",
    "    --weights '/kaggle/working/yolor/runs/train/yolor_p6/weights/best_overall.pt' \\\n",
    "    --conf 0.05 \\\n",
    "    --img-size 1280 \\\n",
    "    --device 0 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 27949.494613,
   "end_time": "2022-01-06T23:38:14.542463",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-01-06T15:52:25.047850",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
